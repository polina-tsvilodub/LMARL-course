{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4\n",
    "\n",
    "This session will provide an overview of LLM agents and approaches to neuro-symbolic AI, bringing together the topics from the previous days.\n",
    "\n",
    "Slides from the fourth lecture can be found [here](https://github.com/polina-tsvilodub/LMARL-course/tree/main/lmarl-course/slides/session4.pdf).\n",
    "\n",
    "The discussion of the day will be on the paper by [Yao et al. (2023). ReAct: Synergizing reasoning and acting in language models](https://arxiv.org/abs/2210.03629)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 4.1.: LLM agents & NeSy architectures</span></strong>\n",
    ">\n",
    "> 1. Do you think that LLM agents in the sense in which they were discussed today are agents (according to definitions and properties form day 1)? Why (not)? \n",
    ">\n",
    "> 2. Do you think applications that are called LLM agents need to be agentic?\n",
    ">\n",
    "> 3. What speaks in favor, what speaks against calling LLM generations \"reasoning\"? Name two aspects.\n",
    ">\n",
    "> 4. Which tools do you think could be used with an LLM to build an LLM+tool-based cognitive architecture?\n",
    ">\n",
    "> 5. What is the difference between an LLM agent and a few-shot prompted (vanilla) LLM?\n",
    ">\n",
    "> 6. For which tasks do you think would the ReAct prompting strategy work (not) well? Name one example each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 4.2.: Conceptualizing and LLM agent</span></strong>\n",
    ">\n",
    "> In the following, your task is to conceptualize the structure of a system (agent) designed for a specific task. Please describe the structure of your system in words, or pseudo-code, or a box-and-arrow diagram.\n",
    ">\n",
    "> Your task is to write a step-by-step guide / blueprint for an LLM based agent that will put all important appointments from your email to your Google Calendar, but will filter out spam appointments from emails from your former school. The agent should make sure there are no scheduling conflicts, and inform the user if there are conflicts.\n",
    "> \n",
    "> Your agent can be equipped with the following **tools**: interface to your email (accessing new incoming emails, writing emails), standard LLM calls to a model of your choice which will follow your prompts, access to your calendar (read and write)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 4.3.: Using LangChain</span></strong>\n",
    ">\n",
    "> For a basic example of how to use langchain, see the exercise sheet [here](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/05a-agents.html). Note that part of the code involve using API keys for different LLMs, so it might rather be useful as a conceptual example starting point. There are exercises with opne-source models accessed through HuggingFace, too. Disclaimer: since the sheet is from a few months ago and Langchain is under active development, some things might be deprecated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
