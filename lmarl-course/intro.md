# Course overview: LLMs, agents & RL

This course taught as a block seminar over the course of one week at Uni TÃ¼bingen will look at different approaches and aspects of agent modeling, i.e., building agents that complete various tasks in an environment in a goal-directed way. The course will cover approaches from classical cognitive science (e.g., discuss cognitive architectures like SOAR), RL (e.g., agents playing Atari-style games), as well as recent Large Language Model-based (LLM) agents (e.g., ToolFormer, or Generative Agents).
The course will provide a high-level recap of LLMs, but familiarity with NLP and LLMs is recommended for this course. Intermediate programming skills are strongly encouraged.

## Intended audience

The course is intended for advanced bachelor students and master students interested in interdisciplinary topics in computational cognitive science and AI.
The course is intended to be a mix of lectures, paper discussions and hands-on tasks, as provided through this webbook. 


## Schedule

The overview of overall topics by day is below.

1. Introduction: what are agents?
2. Cognitive architectures
3. RL
4. LLM agents

## Further materials

Materials for this course are inspired by the following courses:

* [AI Agents and Simulations by J.S. Park](https://joonspk-research.github.io/cs222-fall24/index.html)
* [EMNLP 2024 tutorial on language agents](https://language-agent-tutorial.github.io/)
* [HuggingFace course on agents](https://huggingface.co/learn/agents-course/en/unit1/introduction)
* Outputs from a certain language model inspired some aspects of the materials, too.

For more in-depth recap or introduction of LLMs, please refer to, e.g., [this webbook](https://cogsciprag.github.io/Understanding-LLMs-course/intro.html) I co-authored and the resources listed therein.